{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - list layers to transform dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # transform uint8 to tensor\n",
    "    transforms.Normalize(0.5, 0.5) # normalize the pixels\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - download the mnist dataset\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True) # for training\n",
    "val_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True) # for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - load dataset into packages\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # package the dataset into 64 packages and shuffle it\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False) # the same with train_loader, without shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model and its hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - cnn model class\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self): # model layers structure\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1) # conv1 mask\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1) # conv2 mask\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # pooling mask\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1) # conv3 mask\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1) # conv4 mask\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # pooling mask\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128) # fully linear layer\n",
    "        self.fc2 = nn.Linear(128, 10) # fully linear layer\n",
    "        self.relu = nn.ReLU() # activation layer\n",
    "    def forward(self, x): # model data flow controls\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 64 * 7 * 7) # reshape the data into flatten 1d\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - instantiate the model, loss and optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 160.0640359185636\n",
      "epoch 1, loss: 40.05339048654423\n",
      "epoch 2, loss: 28.077032206609147\n",
      "epoch 3, loss: 21.980355236231844\n",
      "epoch 4, loss: 16.341470628576644\n"
     ]
    }
   ],
   "source": [
    "# 1 - train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device) # if gpu is available move model to it\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train() # enter the model into training mode\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader: # enter the train loader\n",
    "        images, labels = images.to(device), labels.to(device) # if gpu is available move images and labels to it\n",
    "        preds = model(images) # model predictions\n",
    "        loss = criterion(preds, labels) # calculate the error\n",
    "        optimizer.zero_grad() # cleaning the previous gradient\n",
    "        loss.backward() # jump to the backward\n",
    "        optimizer.step() # and improve the model with backward\n",
    "        running_loss += loss.item() # register the losses\n",
    "    print(f\"epoch {epoch}, loss: {running_loss}\") # print out each epoch loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the total 10000, we got 9921 correct answer\n"
     ]
    }
   ],
   "source": [
    "# 2 - valid the model\n",
    "model.eval() # enter the model into validation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device) # again move the val_dataset into gpu\n",
    "        preds = model(images) # get model predictions\n",
    "        _, predicts = torch.max(preds, 1) # extract only the predictions essential\n",
    "        correct += (predicts == labels).sum().item() # and sum the correct answer\n",
    "        total += labels.size(0) # sum up total images quantity\n",
    "    print(f\"for the total {total}, we got {correct} correct answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3 - visualize the validation predictions\n",
    "examples = iter(val_loader) # iterate the validation loader\n",
    "images, labels = next(examples) # getting images and labels by the iter\n",
    "images, labels = images.to(device), labels.to(device) # moving images and labels to gpu\n",
    "with torch.no_grad(): # disable gradient\n",
    "    preds = model(images) # getting model predictions\n",
    "    w, preds_label = torch.max(preds, 1) # getting model predictions labels\n",
    "    #print(nn.functional.softmax(preds, dim=0))\n",
    "fig, axes = plt.subplots(1, 6, figsize=(12, 4)) # 1 row 6 columns\n",
    "for i in range(6):\n",
    "    axes[i].imshow(images[i].cpu().squeeze(), cmap=\"gray\") # convert image to gray scale\n",
    "    axes[i].set_title(f\"Pred: {preds_label[i].item()}\") # title each image\n",
    "    axes[i].axis(\"off\") # hide axis ticks and labels to make image more cleaner\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
